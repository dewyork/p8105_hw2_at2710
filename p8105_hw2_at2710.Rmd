---
title: "Homework 2"
author: "Anusorn Thanataveerat"
date: '2018-09-25'
output:
github_document:
toc: true
toc_float: true
code_folding: hide
---

# Problem 1

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable

```{r Load_Package, include = FALSE, message = FALSE}
library(tidyverse)
library(gridExtra)
library(readxl)
library(knitr)
library(p8105.datasets)
library(janitor)
library(lubridate)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```
```{r problem_1, message = FALSE}
original_dat <-
  read_csv('./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv') %>% clean_names()
  
  subset_dat <-
  original_dat %>% select(line:entry, vending, ada, ada_notes) %>%
  mutate(entry = ifelse(entry == 'YES', TRUE, FALSE))
  dedup_subset_dat <-
  subset_dat %>% arrange(line, station_name, desc(ada)) %>%  distinct(line, station_name, .keep_all = TRUE) 
```

Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

**Answer**:Once downloaded, the data set consists of `r ncol(original_dat)` variables and `r nrow(original_dat)` observations. These are information on all the entrace to all the subway stations in NYC so each station could have multiple rows of information depending on the number of entrance. We further included only the variables as suggested and the number of variables came down to `r ncol(subset_dat)`. Still, the data isn't in the tidy format; the *route* variables could be formatted as having the name of each train as the column with an input as YES/NO in a row. Also, At this point, we noticed rows with identical input of a combination of *line* and *station name* thus we de-duplicated based on those two variables and ended up with **`r nrow(dedup_subset_dat)`** unique stations in the NYC subway system. There are `r sum(dedup_subset_dat$ada)` stations (`r round(100* sum(dedup_subset_dat$ada)/nrow(dedup_subset_dat),2)` %) which are ADA compliant.

What proportion of station entrances / exits without vending allow entrance?

**Answer**: Of all the `r nrow(original_dat)` entrances, `r sum(original_dat$vending == 'NO')` have no vending machine but `r sum(original_dat$entry == 'YES' & original_dat$vending == 'NO')` (`r round(sum(original_dat$entry == 'YES' & original_dat$vending == 'NO')*100/sum(original_dat$vending == 'NO'),2)`%) of that do allow for entry.  

Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? How many are ADA compliant?

```{r}
reformat_dedup_subset <-
  dedup_subset_dat %>% gather(key = route, value = Line, route1:route11) %>%
  filter(!is.na(Line)) %>% select(-route) %>%
  mutate(true = TRUE, Line = as.factor(Line)) %>%
  spread(key = c(Line), value = true) 
```

**Answer**: There are `r sum(reformat_dedup_subset$A, na.rm = TRUE)` stations that the A train serves `r reformat_dedup_subset %>% filter(A == TRUE & ada == TRUE) %>% nrow()` of which are ADA compliant.

# Problem 2
```{r problem_2}
Trash_Wheel <-
  readxl::read_excel(
  "./Data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
  sheet = 'Mr. Trash Wheel',
  range = cell_cols("A:N")
  ) %>% clean_names() %>% filter(!is.na(dumpster) & !is.na(date)) %>%
  mutate(sports_balls = as.integer(round(sports_balls, 0)),
  year = lubridate::year(date))

Trash_Wheel_new <- Trash_Wheel %>% filter(year > 2015)
  Precip_2017 <-
  readxl::read_excel(
  "./Data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
  sheet = '2017 Precipitation',
  range = "A2:B14"
  ) %>% filter(!is.na(Total)) %>% mutate(year = 2017)
  
  Precip_2016 <-
  readxl::read_excel(
  "./Data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
  sheet = '2016 Precipitation',
  range = "A2:B14"
  ) %>% mutate(year = 2016)
  Precip_combine <-
  bind_rows(Precip_2016, Precip_2017) %>% mutate(Month = month.name[Month]) %>%
  select(month = Month, year, precip = Total)

```

Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

**Answer**: The Trash wheel data set contains the information on the types and amount of garbage/waste collected in each dumpster filled from the Trash wheel from May-2014 to August-2017. it consists of `r nrow(Trash_Wheel)` observations with `r ncol(Trash_Wheel)` variables. The precipitaton data consists of monthly precipitation level from 2016 to August 2017 (`r nrow(Precip_combine)` rows and `r ncol(Precip_combine)` variables) 
```{r table_top_ten_dumpsters, message = FALSE}
# Trash_Wheel %>% group_by(month, year) %>% tally() %>% ungroup() %>% arrange(desc(n)) %>% top_n(10) %>% 
#   rename(number_dumpster = n) %>% kable()
```

Since we only use precipitation data from 2016 to August/2017, we restricted the data in the Trash wheel to reflect the same timeframe. Now the new Trash wheel data consists of `r nrow(Trash_Wheel_new)` observations. If we look at the top five months which have the highest number of dumpsters,  
```{r message = FALSE}
Trash_Wheel %>% group_by(month) %>% tally() %>% ungroup() %>% arrange(desc(n)) %>% top_n(5) %>% 
  rename(number_dumpster = n) %>% kable()
```

These months are between April and August (hurricane season) which is in agreement with what was given in the assignment which states "the amount of trash the device receives is highly dependent on rainfall". However, when we look at the top five months with highest precipitation level during 2016-2017, 
```{r table_top_ten_precip, message = FALSE}
Precip_combine %>% group_by(month) %>% tally(precip) %>% ungroup() %>%  arrange(desc(n)) %>% top_n(5) %>%   rename(precip_level = n) %>% kable()
```

we found that February and March have high precipitation level but those didn't translate into a larger amount of garbage. This implies that the level of precipitation doesn't solely explain the amount of garbage; there must be other explanatory variables which contribute to the outcome.
The total precipitation in 2017 (up to month August) is `r sum(Precip_2017$Total)`. and the median number of sports balls in a dumpster in 2016 is `r Trash_Wheel_new %>% filter(year == 2016) %>% summarise(sports_balls_median = median(sports_balls))`

# Problem 3
```{r load_brfss, message = FALSE}
data("brfss_smart2010")
health_overall <-
brfss_smart2010 %>% clean_names() %>%  filter(str_detect(topic, c("Overall Health"))) %>%
select(-c(
class:question,
sample_size,
confidence_limit_low:geo_location
))

health_overall_wide_fmt <- health_overall %>% spread(response, data_value) %>% rename(Very_Good = `Very good`) %>% 
  mutate(excellent_Vgood_prop = (Excellent + Very_Good)/(Excellent  + Fair +  Good +  Poor + Very_Good)) %>% 
  select(year, state = locationabbr, county = locationdesc, Excellent, Very_Good, Good, Fair, Poor, excellent_Vgood_prop)
```

How many unique locations are included in the dataset? 

**Answer**`r length(unique(health_overall_wide_fmt$county))`

Is every state represented? What state is observed the most?

**Answer** Data comes from `r length(unique(health_overall_wide_fmt$state))` states (50 states plus district of columbia) with `r names(sort(table(health_overall_wide_fmt$state), decreasing = TRUE)[1])` being observed the most (`r sort(table(health_overall_wide_fmt$state), decreasing = TRUE)[1]` times).

In 2002, what is the median of the “Excellent” response value?

**Answer** `r health_overall_wide_fmt %>% filter(year == 2002) %>% summarise(excellent_median = median(Excellent, na.rm = TRUE))`

Make a histogram of “Excellent” response values in the year 2002.

```{r histogram, message = FALSE}
health_overall_wide_fmt %>% filter(year == 2002 & !is.na(Excellent)) %>% ggplot(aes(x = Excellent)) + geom_histogram()
```

Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.
```{r scatterplot, message = FALSE}
health_overall_wide_fmt %>% filter(county %in% c('NY - Queens County', 'NY - New York County')) %>% 
  mutate(excellent_prop = Excellent/(Excellent  + Fair +  Good +  Poor + Very_Good)) %>% 
  ggplot(aes(x = year, y = excellent_prop, color = county)) + geom_jitter() + 
  ylab("Proportion 'Excellent' response")
```

ps. It does seem like New York county dwellers tend to rate their health higher than those who live in Queens!
